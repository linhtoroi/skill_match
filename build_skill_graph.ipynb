{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pymongo import MongoClient\n",
    "from googletrans import Translator\n",
    "from bson.objectid import ObjectId\n",
    "import tqdm\n",
    "import re\n",
    "from nltk import ngrams\n",
    "import Levenshtein\n",
    "import pickle\n",
    "import os\n",
    "from gensim.test.utils import lee_corpus_list\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "import json\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11731"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('ontology.json', 'r')\n",
    "g_onto = json.loads(f.read())\n",
    "\n",
    "def get_all_skill_from_onto(d_in, skill, exception, level):\n",
    "    for k in d_in:\n",
    "        if type(d_in[k]) == dict:\n",
    "            level+=1\n",
    "            skill = get_all_skill_from_onto(d_in[k], skill, exception, level)\n",
    "            level-=1\n",
    "            if k not in exception and level >=2:\n",
    "                skill.add(k)\n",
    "                \n",
    "    return skill\n",
    "len(get_all_skill_from_onto(g_onto, set(), ['database', ''], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ontology.json', 'r')\n",
    "g_onto = json.loads(f.read())\n",
    "\n",
    "def fix_g_onto(d_in, new_onto, exception, level):\n",
    "    for k in d_in:\n",
    "        if type(d_in[k]) == dict:\n",
    "            level+=1\n",
    "            new_onto = fix_g_onto(d_in[k], new_onto, exception, level)\n",
    "            level-=1\n",
    "            \n",
    "            temp=[]\n",
    "            for i in d_in[k].keys():\n",
    "                if i in exception and level >=2:\n",
    "                    temp.append(i)\n",
    "            \n",
    "            for i in temp:\n",
    "                d_in[k].pop(i, None)\n",
    "                \n",
    "    return d_in\n",
    "new_onto = fix_g_onto(g_onto, {}, ['smartphones', 'smart phone'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ontology.json', 'r')\n",
    "g_onto = json.loads(f.read())\n",
    "\n",
    "def fix_g_onto(d_in, new_onto, exception, level):\n",
    "    for k in d_in:\n",
    "        if type(d_in[k]) == dict:\n",
    "            level+=1\n",
    "            fix_g_onto(d_in[k], new_onto, exception, level)\n",
    "            level-=1\n",
    "            \n",
    "            temp=[]\n",
    "            for i in d_in[k].keys():\n",
    "                if i in exception and level >=2:\n",
    "                    print(i)\n",
    "                \n",
    "    return\n",
    "fix_g_onto(new_onto, {}, ['smartphones', 'smart phone'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(host='103.252.1.144', username='admin', password = 'CIST2o20')\n",
    "cb = client['human_resources']['career_builder']\n",
    "cv = cb.find({'eng_experience':{'$exists':True}, 'fulltext':{'$regex':'.*developer.*'}})\n",
    "jpt = client['human_resources']['job_posting_topcv']\n",
    "jd = jpt.find({'eng_job_description':{'$regex':'.*developer.*'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSO_classifier():\n",
    "    def __init__(self, path='ontology.json'):\n",
    "        f = open(path, 'r')\n",
    "        self.g_onto = json.loads(f.read())\n",
    "        self.g_onto = self.fix_g_onto(g_onto, {}, ['smartphones', 'smart phone'], 0)\n",
    "        self.skill = self.get_all_skill_from_onto(self.g_onto, set(),['database', 'knowledge', 'research', 'drawing', 'engineer', 'desktop'], 0)\n",
    "\n",
    "\n",
    "    def get_all_skill_from_onto(self, d_in, skill, exception, level):\n",
    "        for k in d_in:\n",
    "            if type(d_in[k]) == dict:\n",
    "                level+=1\n",
    "                skill = self.get_all_skill_from_onto(d_in[k], skill, exception, level)\n",
    "                level-=1\n",
    "                if k not in exception and level >=2:\n",
    "                    skill.add(k)\n",
    "        return skill\n",
    "\n",
    "    def fix_g_onto(self, d_in, new_onto, exception, level):\n",
    "        for k in d_in:\n",
    "            if type(d_in[k]) == dict:\n",
    "                level+=1\n",
    "                new_onto = self.fix_g_onto(d_in[k], new_onto, exception, level)\n",
    "                level-=1\n",
    "                \n",
    "                temp=[]\n",
    "                for i in d_in[k].keys():\n",
    "                    if i in exception and level >=2:\n",
    "                        temp.append(i)\n",
    "                \n",
    "                for i in temp:\n",
    "                    d_in[k].pop(i, None)\n",
    "                    \n",
    "        return d_in\n",
    "\n",
    "    def get_skill_by_concept_similarity(self, sentence):\n",
    "        sentence = re.sub(r\"[-()\\\"/@;:<>{}`=~|.!?,]\", \" \", sentence).lower()\n",
    "\n",
    "        uni_gram = ngrams(sentence.split(), 1)\n",
    "        bi_gram = ngrams(sentence.split(), 2)\n",
    "        tri_gram = ngrams(sentence.split(), 3)\n",
    "\n",
    "        uni_gram = [i[0] for i in list(uni_gram)]\n",
    "        bi_gram = ['{} {}'.format(i[0],i[1]) for i in list(bi_gram)]\n",
    "        tri_gram = ['{} {} {}'.format(i[0],i[1], i[2]) for i in list(tri_gram)]\n",
    "        \n",
    "        n_gram = uni_gram + bi_gram + tri_gram\n",
    "\n",
    "        skill_find_out = set()\n",
    "        \n",
    "        for i in n_gram:\n",
    "            for o_k in self.skill:\n",
    "                if Levenshtein.ratio(i, o_k) > 0.94:\n",
    "                    skill_find_out.add(o_k)\n",
    "\n",
    "        return skill_find_out\n",
    "\n",
    "    \n",
    "    def build_graph(self, onto, skill, level, skill_same_level, graph):\n",
    "        for i in onto:\n",
    "            level+=1\n",
    "            if type(onto[i]) == dict:\n",
    "                level, skill_same_level, graph = self.build_graph(onto[i], skill, level, skill_same_level, graph)\n",
    "    \n",
    "                pop_ = []\n",
    "                for j in graph.keys():\n",
    "                    if j in onto[i].keys():\n",
    "                        pop_.append(j)\n",
    "                for j in pop_:\n",
    "                    if j!= '':\n",
    "                        tmp = graph[j]\n",
    "                        graph.pop(j, None)\n",
    "                        if i not in graph:\n",
    "                            graph[i]={}\n",
    "                        graph[i][j] = tmp\n",
    "\n",
    "                if i in skill:\n",
    "                    if level not in skill_same_level:\n",
    "                        skill_same_level[level]=set()\n",
    "                    skill_same_level[level].add(i)\n",
    "\n",
    "                if level+1 in skill_same_level:\n",
    "                    if len(skill_same_level[level+1]) > 0:\n",
    "                        way_1 = False\n",
    "                        if i not in graph:\n",
    "                            graph[i] = list(skill_same_level[level+1])\n",
    "                        else:\n",
    "                            for j in skill_same_level[level+1]:\n",
    "                                if j in graph[i]:\n",
    "                                    way_1 = True\n",
    "                            if not way_1 and len(graph[i])>0 and type(graph[i])==dict:\n",
    "                                for k in skill_same_level[level+1]:\n",
    "                                    graph[i][k]=[k]\n",
    "                        \n",
    "                        skill_same_level[level+1]=set()\n",
    "                \n",
    "                level-=1\n",
    "        return level, skill_same_level, graph\n",
    "    \n",
    "    def count_skill_from_graph(self, graph, skill, level, new_graph, cnt=None):\n",
    "        if(type(graph) == dict):\n",
    "            for i in graph.keys():\n",
    "                level+=1\n",
    "                if cnt!=None:\n",
    "                    if level==3:\n",
    "                        cnt.append({i:0})\n",
    "                \n",
    "                if type(graph[i]) == dict:\n",
    "                    skill, cnt, level, new_graph = self.count_skill_from_graph(graph[i], skill, level, new_graph, cnt) \n",
    "                    level-=1  \n",
    "                else:\n",
    "                    for j in graph[i]:\n",
    "                        skill.add(j)\n",
    "                        if cnt!=None and len(cnt)>0:\n",
    "                            cnt[-1][list(cnt[-1].keys())[0]] += 1\n",
    "                    level-=1            \n",
    "\n",
    "        return skill, cnt, level, new_graph\n",
    "\n",
    "    def get_skill_from_graph(self, graph, skill, level, new_graph, cnt=None):\n",
    "        if type(graph) == dict:\n",
    "            for i in graph.keys():\n",
    "                level+=1\n",
    "                if cnt!=None:\n",
    "                    if level==3:\n",
    "                        cnt.append({i:0})\n",
    "                \n",
    "                if type(graph[i]) == dict:\n",
    "                    skill, cnt, level, new_graph = self.get_skill_from_graph(graph[i], skill, level, new_graph, cnt) \n",
    "                    level-=1  \n",
    "                else:\n",
    "                    for j in graph[i]:\n",
    "                        skill.add(j)\n",
    "                        if cnt!=None and len(cnt)>0:\n",
    "                            cnt[-1][list(cnt[-1].keys())[0]] += 1\n",
    "                    level-=1            \n",
    "\n",
    "            return skill, cnt, level, new_graph\n",
    "        else:\n",
    "            return graph\n",
    "\n",
    "    def build_skill_graph(self, all_skill):\n",
    "        new_graph = {}\n",
    "        graph =  self.build_graph(g_onto, all_skill, 0, {}, {})[2]\n",
    "        count_domain = self.count_skill_from_graph(graph, set(), 0, {}, [])[1]\n",
    "        not_cancel = True\n",
    "        \n",
    "        while len(all_skill)>0 and not_cancel:\n",
    "            \n",
    "            max_domain = {'domain': '', 'count': 0}\n",
    "            for i in count_domain:\n",
    "                if i[list(i.keys())[0]] > max_domain['count']:\n",
    "                    max_domain['domain'] = list(i.keys())[0]\n",
    "                    max_domain['count'] = i[list(i.keys())[0]]\n",
    "\n",
    "            for i in graph:\n",
    "                for k in graph[i]:\n",
    "                    for j in graph[i][k]:\n",
    "                        if j == max_domain['domain']:\n",
    "                            sub_skill = self.get_skill_from_graph(graph[i][k][j], set(), 0, {})[0]\n",
    "                            if i not in new_graph:\n",
    "                                new_graph[i] = {}\n",
    "                            if k not in new_graph[i]:\n",
    "                                new_graph[i][k] = {}\n",
    "                            if j not in new_graph[i][k]:\n",
    "                                new_graph[i][k][j] = {}\n",
    "                            \n",
    "                            new_graph[i][k][j] = graph[i][k][j]\n",
    "\n",
    "            if type(sub_skill) == str:\n",
    "                all_skill=all_skill-set([sub_skill])\n",
    "            else:\n",
    "                all_skill=all_skill-sub_skill\n",
    "\n",
    "            graph = self.build_graph(g_onto, all_skill, 0, {}, {})[2]\n",
    "\n",
    "            count_domain = self.count_skill_from_graph(graph, set(), 0, {}, [])[1]\n",
    "            \n",
    "            if len(count_domain)==0:\n",
    "                not_cancel = False\n",
    "        return new_graph\n",
    "\n",
    "                                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology = {'A':[], 'JD': [], 'R': []}\n",
    "\n",
    "c = {'Profile': None, 'Work_history': None, 'Education': None, 'Course': None, 'Skills': {}, 'Pos': None, 'Others': None}\n",
    "d = {'Information': None, 'Descriptions': None, 'Required': None, 'Skills': {}}\n",
    "\n",
    "cso_classifier = CSO_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = cso_classifier.get_skill_by_concept_similarity(' '.join(cv[0]['eng_experience']+cv[0]['eng_skills']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'general': {'computer science': {'software engineering': {'software design': {'software architecture': {'software development': ['software team'],\n",
       "      'software development process': ['software team'],\n",
       "      'software development life cycle': ['software team'],\n",
       "      'software development project': ['software team'],\n",
       "      'software developer': ['software developer']},\n",
       "     'software product': {'software development': ['software team'],\n",
       "      'software development process': ['software team'],\n",
       "      'software development life cycle': ['software team'],\n",
       "      'software development project': ['software team']},\n",
       "     'software project': {'software development': ['software team'],\n",
       "      'software development process': ['software team'],\n",
       "      'software development life cycle': ['software team'],\n",
       "      'software development project': ['software team']},\n",
       "     'software process': {'software development': ['software team'],\n",
       "      'software development process': ['software team'],\n",
       "      'software development life cycle': ['software team'],\n",
       "      'software development project': ['software team']},\n",
       "     'software system': ['software system']}},\n",
       "   'computer system': {'database system': ['database management'],\n",
       "    'information system': {'management information system': ['database management']},\n",
       "    'telecommunication system': {'telecommunication network': {'mobile telecommunication system': {'smartphone': ['android']}}},\n",
       "    'database': ['database management']},\n",
       "   'artificial intelligence': {'machine learning': {'pattern recognition': {'face recognition': ['face detection']}},\n",
       "    'programming language': ['python', 'c++']},\n",
       "   'software': {'computer control system': {'numerical control system': ['cnc']},\n",
       "    'gps': ['in']},\n",
       "   'operating system': ['linux']},\n",
       "  'mobile': {'android': {'mobile sensor': ['camera']}},\n",
       "  'softskill': {'softskill': {'communication': {'using foreign language': ['english']}}}}}"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cso_classifier.build_skill_graph(skills)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96350e89b918eef37b6e497c0b867bc0d181ddadcfc87ab65b01a89441f72824"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('venv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
