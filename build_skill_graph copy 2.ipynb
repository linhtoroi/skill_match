{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pymongo import MongoClient\n",
    "from googletrans import Translator\n",
    "from bson.objectid import ObjectId\n",
    "import tqdm\n",
    "import re\n",
    "from nltk import ngrams\n",
    "import Levenshtein\n",
    "import pickle\n",
    "import os\n",
    "from gensim.test.utils import lee_corpus_list\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "import json\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12666"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('ontology_linked_in_general.json', 'r')\n",
    "g_onto = json.loads(f.read())\n",
    "\n",
    "def get_all_skill_from_onto(d_in, skill, exception, level):\n",
    "    for k in d_in:\n",
    "        if type(d_in[k]) == dict:\n",
    "            level+=1\n",
    "            skill = get_all_skill_from_onto(d_in[k], skill, exception, level)\n",
    "            level-=1\n",
    "\n",
    "            if k not in exception and level >=3:\n",
    "                skill.add(k)\n",
    "                \n",
    "    return skill\n",
    "len(get_all_skill_from_onto(g_onto, set(), ['database', ''], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7052, 0, 6, 68, 571, 6407, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cnt(dict_, cnt_, level, cnt_level_1, cnt_level_2, cnt_level_3, cnt_level_4, cnt_level_5):\n",
    "    for i in dict_:\n",
    "        if type(dict_[i]) == dict:\n",
    "            level+=1\n",
    "            cnt_, level, cnt_level_1, cnt_level_2, cnt_level_3, cnt_level_4, cnt_level_5 = cnt(dict_[i], cnt_, level, cnt_level_1, cnt_level_2, cnt_level_3, cnt_level_4, cnt_level_5)\n",
    "            cnt_+=1\n",
    "            if level==1:\n",
    "                cnt_level_1+=1\n",
    "            elif level==2:\n",
    "                cnt_level_2+=1\n",
    "            elif level==3:\n",
    "                cnt_level_3+=1\n",
    "            elif level==4:\n",
    "                cnt_level_4+=1\n",
    "            elif level==5:\n",
    "                cnt_level_5+=1\n",
    "            level-=1\n",
    "    return cnt_, level, cnt_level_1, cnt_level_2, cnt_level_3, cnt_level_4, cnt_level_5\n",
    "\n",
    "cnt(g_onto['all']['linked_in'], 0, 0, 0, 0, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = []\n",
    "# cnt_1 = []\n",
    "# for i in g_onto['all']['linked_in']:\n",
    "#     for j in g_onto['all']['linked_in'][i]:\n",
    "#         for k in g_onto['all']['linked_in'][i][j]:\n",
    "#             if k == 'Software_of_'+j:\n",
    "#                 cnt_1.append(len(g_onto['all']['linked_in'][i][j][k]))\n",
    "#             cnt.append(len(g_onto['all']['linked_in'][i][j][k]))\n",
    "# import numpy as np\n",
    "# np.sum(cnt)-np.sum(cnt_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ontology_linked_in_general.json', 'r')\n",
    "g_onto = json.loads(f.read())\n",
    "\n",
    "def fix_g_onto(d_in, new_onto, exception, level):\n",
    "    for k in d_in:\n",
    "        if type(d_in[k]) == dict:\n",
    "            level+=1\n",
    "            new_onto = fix_g_onto(d_in[k], new_onto, exception, level)\n",
    "            level-=1\n",
    "            \n",
    "            temp=[]\n",
    "            for i in d_in[k].keys():\n",
    "                if i in exception and level >=3:\n",
    "                    temp.append(i)\n",
    "            \n",
    "            for i in temp:\n",
    "                d_in[k].pop(i, None)\n",
    "                \n",
    "    return d_in\n",
    "new_onto = fix_g_onto(g_onto, {}, ['smartphones', 'smart phone'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ontology_linked_in_general.json', 'r')\n",
    "g_onto = json.loads(f.read())\n",
    "\n",
    "def fix_g_onto(d_in, new_onto, exception, level):\n",
    "    for k in d_in:\n",
    "        if type(d_in[k]) == dict:\n",
    "            level+=1\n",
    "            fix_g_onto(d_in[k], new_onto, exception, level)\n",
    "            level-=1\n",
    "            \n",
    "            temp=[]\n",
    "            for i in d_in[k].keys():\n",
    "                if i in exception and level >=3:\n",
    "                    print(i)\n",
    "                \n",
    "    return\n",
    "fix_g_onto(new_onto, {}, ['smartphones', 'smart phone'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(host='103.252.1.144', username='admin', password = 'CIST2o20')\n",
    "cb = client['human_resources']['career_builder']\n",
    "cv = cb.find({'eng_experience':{'$exists':True}, 'fulltext':{'$regex':'.*developer.*'}})\n",
    "jpt = client['human_resources']['job_posting_topcv']\n",
    "jd = jpt.find({'eng_job_description':{'$regex':'.*developer.*'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyxdameraulevenshtein'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-12762f70e098>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyxdameraulevenshtein\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdamerau_levenshtein_distance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalized_damerau_levenshtein_distance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdamerau_levenshtein_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'smtih'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'smith'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# expected result: 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnormalized_damerau_levenshtein_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'smtih'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'smith'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# expected result: 0.2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdamerau_levenshtein_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# expected result: 7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyxdameraulevenshtein'"
     ]
    }
   ],
   "source": [
    "from pyxdameraulevenshtein import damerau_levenshtein_distance, normalized_damerau_levenshtein_distance\n",
    "damerau_levenshtein_distance('smtih', 'smith')  # expected result: 1\n",
    "normalized_damerau_levenshtein_distance('smtih', 'smith')  # expected result: 0.2\n",
    "damerau_levenshtein_distance([1, 2, 3, 4, 5, 6], [7, 8, 9, 7, 10, 11, 4])  # expected result: 7\n",
    "\n",
    "from pyxdameraulevenshtein import damerau_levenshtein_distance_seqs, normalized_damerau_levenshtein_distance_seqs\n",
    "array = ['test1', 'test12', 'test123']\n",
    "damerau_levenshtein_distance_seqs('test', array)  # expected result: [1, 2, 3]\n",
    "normalized_damerau_levenshtein_distance_seqs('test', array)  # expected result: [0.2, 0.33333334, 0.42857143]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSO_classifier():\n",
    "    def __init__(self, path='ontology.json'):\n",
    "        f = open(path, 'r')\n",
    "        self.g_onto = json.loads(f.read())\n",
    "        self.g_onto = self.fix_g_onto(g_onto, {}, ['smartphones', 'smart phone'], 0)\n",
    "        self.skill = self.get_all_skill_from_onto(self.g_onto, set(),['','database', 'knowledge', 'research', 'drawing', 'engineer', 'desktop'], 0)\n",
    "\n",
    "\n",
    "    def get_all_skill_from_onto(self, d_in, skill, exception, level):\n",
    "        for k in d_in:\n",
    "            if type(d_in[k]) == dict:\n",
    "                level+=1\n",
    "                skill = self.get_all_skill_from_onto(d_in[k], skill, exception, level)\n",
    "                level-=1\n",
    "                if k not in exception and level >=3:\n",
    "                    skill.add(k)\n",
    "        return skill\n",
    "\n",
    "    def fix_g_onto(self, d_in, new_onto, exception, level):\n",
    "        for k in d_in:\n",
    "            if type(d_in[k]) == dict:\n",
    "                level+=1\n",
    "                new_onto = self.fix_g_onto(d_in[k], new_onto, exception, level)\n",
    "                level-=1\n",
    "                \n",
    "                temp=[]\n",
    "                for i in d_in[k].keys():\n",
    "                    if i in exception and level >=3:\n",
    "                        temp.append(i)\n",
    "                \n",
    "                for i in temp:\n",
    "                    d_in[k].pop(i, None)\n",
    "                    \n",
    "        return d_in\n",
    "\n",
    "    def get_skill_by_concept_similarity(self, sentence):\n",
    "        sentence = re.sub(r\"[-()\\\"/@;:<>{}`=~|.!?,]\", \" \", sentence).lower()\n",
    "\n",
    "        uni_gram = ngrams(sentence.split(), 1)\n",
    "        bi_gram = ngrams(sentence.split(), 2)\n",
    "        tri_gram = ngrams(sentence.split(), 3)\n",
    "\n",
    "        uni_gram = [i[0] for i in list(uni_gram)]\n",
    "        bi_gram = ['{} {}'.format(i[0],i[1]) for i in list(bi_gram)]\n",
    "        tri_gram = ['{} {} {}'.format(i[0],i[1], i[2]) for i in list(tri_gram)]\n",
    "        \n",
    "        n_gram = uni_gram + bi_gram + tri_gram\n",
    "\n",
    "        skill_find_out = set()\n",
    "        \n",
    "        for i in n_gram:\n",
    "            for o_k in self.skill:\n",
    "                if Levenshtein.ratio(i, o_k) > 0.94:\n",
    "                    skill_find_out.add(o_k)\n",
    "\n",
    "        return skill_find_out\n",
    "\n",
    "    \n",
    "    def build_graph(self, onto, skill, level, skill_same_level, graph):\n",
    "        for i in onto:\n",
    "            level+=1\n",
    "            if type(onto[i]) == dict:\n",
    "                level, skill_same_level, graph = self.build_graph(onto[i], skill, level, skill_same_level, graph)\n",
    "    \n",
    "                pop_ = []\n",
    "                for j in graph.keys():\n",
    "                    if j in onto[i].keys():\n",
    "                        pop_.append(j)\n",
    "                for j in pop_:\n",
    "                    if j!= '':\n",
    "                        tmp = graph[j]\n",
    "                        graph.pop(j, None)\n",
    "                        if i not in graph:\n",
    "                            graph[i]={}\n",
    "                        graph[i][j] = tmp\n",
    "\n",
    "                if i in skill:\n",
    "                    if level not in skill_same_level:\n",
    "                        skill_same_level[level]=set()\n",
    "                    skill_same_level[level].add(i)\n",
    "\n",
    "                if level+1 in skill_same_level:\n",
    "                    if len(skill_same_level[level+1]) > 0:\n",
    "                        way_1 = False\n",
    "                        if i not in graph:\n",
    "                            graph[i] = list(skill_same_level[level+1])\n",
    "                        else:\n",
    "                            for j in skill_same_level[level+1]:\n",
    "                                if j in graph[i]:\n",
    "                                    way_1 = True\n",
    "                            if not way_1 and len(graph[i])>0 and type(graph[i])==dict:\n",
    "                                for k in skill_same_level[level+1]:\n",
    "                                    graph[i][k]=[k]\n",
    "                        \n",
    "                        skill_same_level[level+1]=set()\n",
    "                \n",
    "                level-=1\n",
    "        return level, skill_same_level, graph\n",
    "    \n",
    "    def count_skill_from_graph(self, graph, skill, level, new_graph, cnt=None):\n",
    "        if(type(graph) == dict):\n",
    "            for i in graph.keys():\n",
    "                level+=1\n",
    "                if cnt!=None:\n",
    "                    if level==4:\n",
    "                        cnt.append({i:0})\n",
    "                \n",
    "                if type(graph[i]) == dict:\n",
    "                    skill, cnt, level, new_graph = self.count_skill_from_graph(graph[i], skill, level, new_graph, cnt) \n",
    "                    level-=1  \n",
    "                else:\n",
    "                    for j in graph[i]:\n",
    "                        skill.add(j)\n",
    "                        if cnt!=None and len(cnt)>0:\n",
    "                            cnt[-1][list(cnt[-1].keys())[0]] += 1\n",
    "                    level-=1            \n",
    "\n",
    "        return skill, cnt, level, new_graph\n",
    "\n",
    "    def get_skill_from_graph(self, graph, skill, level, new_graph, cnt=None):\n",
    "        if type(graph) == dict:\n",
    "            for i in graph.keys():\n",
    "                level+=1\n",
    "                if cnt!=None:\n",
    "                    if level==4:\n",
    "                        cnt.append({i:0})\n",
    "                \n",
    "                if type(graph[i]) == dict:\n",
    "                    skill, cnt, level, new_graph = self.get_skill_from_graph(graph[i], skill, level, new_graph, cnt) \n",
    "                    level-=1  \n",
    "                else:\n",
    "                    for j in graph[i]:\n",
    "                        skill.add(j)\n",
    "                        if cnt!=None and len(cnt)>0:\n",
    "                            cnt[-1][list(cnt[-1].keys())[0]] += 1\n",
    "                    level-=1            \n",
    "\n",
    "            return skill, cnt, level, new_graph\n",
    "        else:\n",
    "            return graph\n",
    "\n",
    "    def build_skill_graph(self, all_skill):\n",
    "        new_graph = {}\n",
    "        graph =  self.build_graph(g_onto, all_skill, 0, {}, {})[2]\n",
    "        count_domain = self.count_skill_from_graph(graph, set(), 0, {}, [])[1]\n",
    "        not_cancel = True\n",
    "        \n",
    "        while len(all_skill)>0 and not_cancel:\n",
    "            \n",
    "            max_domain = {'domain': '', 'count': 0}\n",
    "            for i in count_domain:\n",
    "                if i[list(i.keys())[0]] > max_domain['count']:\n",
    "                    max_domain['domain'] = list(i.keys())[0]\n",
    "                    max_domain['count'] = i[list(i.keys())[0]]\n",
    "            \n",
    "            for i in graph:\n",
    "                for k in graph[i]:\n",
    "                    for l in graph[i][k]:\n",
    "                        for j in graph[i][k][l]:\n",
    "                            if j == max_domain['domain']:\n",
    "                                sub_skill = self.get_skill_from_graph(graph[i][k][l][j], set(), 0, {})[0]\n",
    "                                if i not in new_graph:\n",
    "                                    new_graph[i] = {}\n",
    "                                if k not in new_graph[i]:\n",
    "                                    new_graph[i][k] = {}\n",
    "                                if l not in new_graph[i][k]:\n",
    "                                    new_graph[i][k][l] = {}\n",
    "                                if j not in new_graph[i][k][l]:\n",
    "                                    new_graph[i][k][l][j] = {}\n",
    "                                \n",
    "                                new_graph[i][k][l][j] = graph[i][k][l][j]\n",
    "            \n",
    "            if type(sub_skill) == str:\n",
    "                all_skill=all_skill-set([sub_skill])\n",
    "            else:\n",
    "                all_skill=all_skill-sub_skill\n",
    "\n",
    "            graph = self.build_graph(g_onto, all_skill, 0, {}, {})[2]\n",
    "\n",
    "            count_domain = self.count_skill_from_graph(graph, set(), 0, {}, [])[1]\n",
    "            \n",
    "            if len(count_domain)==0:\n",
    "                not_cancel = False\n",
    "        return new_graph\n",
    "\n",
    "                                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology = {'A':[], 'JD': [], 'R': []}\n",
    "\n",
    "c = {'Profile': None, 'Work_history': None, 'Education': None, 'Course': None, 'Skills': {}, 'Pos': None, 'Others': None}\n",
    "d = {'Information': None, 'Descriptions': None, 'Required': None, 'Skills': {}}\n",
    "\n",
    "cso_classifier = CSO_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = cso_classifier.get_skill_by_concept_similarity(' '.join(cv[0]['eng_experience']+cv[0]['eng_skills']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': {'general': {'computer science': {'software engineering': {'software design': {'software architecture': {'software development': ['software team'],\n",
       "       'software development process': ['software team'],\n",
       "       'software development life cycle': ['software team'],\n",
       "       'software development project': ['software team'],\n",
       "       'software developer': ['software developer']},\n",
       "      'software product': {'software development': ['software team'],\n",
       "       'software development process': ['software team'],\n",
       "       'software development life cycle': ['software team'],\n",
       "       'software development project': ['software team']},\n",
       "      'software project': {'software development': ['software team'],\n",
       "       'software development process': ['software team'],\n",
       "       'software development life cycle': ['software team'],\n",
       "       'software development project': ['software team']},\n",
       "      'software process': {'software development': ['software team'],\n",
       "       'software development process': ['software team'],\n",
       "       'software development life cycle': ['software team'],\n",
       "       'software development project': ['software team']},\n",
       "      'software system': ['software system']}},\n",
       "    'computer system': {'database system': ['database management'],\n",
       "     'information system': {'management information system': ['database management']},\n",
       "     'telecommunication system': {'telecommunication network': {'mobile telecommunication system': {'smartphone': ['android']}}},\n",
       "     'database': ['database management']},\n",
       "    'artificial intelligence': {'machine learning': {'pattern recognition': {'face recognition': ['face detection']}},\n",
       "     'programming language': ['python', 'c++']},\n",
       "    'software': {'computer control system': {'numerical control system': ['cnc']},\n",
       "     'gps': ['in']},\n",
       "    'operating system': ['linux']},\n",
       "   'mobile': {'android': {'mobile sensor': ['camera']}},\n",
       "   'softskill': {'softskill': {'communication': {'using foreign language': ['english']}}}},\n",
       "  'linked_in': {'creative': {'product and manufacturing': ['manufacturing']},\n",
       "   'business': {'business analysis and strategy': ['product management'],\n",
       "    'business software and tools': ['devices']}}}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cso_classifier.build_skill_graph(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all': {'general': {'computer science': {'artificial intelligence': {'machine learning': {'pattern recognition': {'face recognition': ['face detection']}}, 'programming language': ['python', 'c++']}, 'data science': {'programming language': ['python']}, 'computer network': {'wireless telecommunication system': {'communication channel %28information theory%29': {'mobile telecommunication system': {'smartphone': ['android']}}}}, 'software engineering': {'software design': {'software architecture': {'software development': ['software team'], 'software development process': ['software team'], 'software development life cycle': ['software team'], 'software development project': ['software team'], 'software developer': ['software developer']}, 'software product': {'software development': ['software team'], 'software development process': ['software team'], 'software development life cycle': ['software team'], 'software development project': ['software team']}, 'software project': {'software development': ['software team'], 'software development process': ['software team'], 'software development life cycle': ['software team'], 'software development project': ['software team']}, 'software process': {'software development': ['software team'], 'software development process': ['software team'], 'software development life cycle': ['software team'], 'software development project': ['software team']}, 'software system': ['software system']}}, 'computer programming': {'computer programming language': {'programming language': ['python', 'c++']}, 'object oriented programming': ['software system'], 'high level language': {'scripting language': ['python']}}, 'computer aided design': {'computer aided manufacturing': {'machining': {'numerical control system': ['cnc']}}}, 'computer system': {'database system': ['database management'], 'information system': {'management information system': ['database management']}, 'telecommunication system': {'telecommunication network': {'mobile telecommunication system': {'smartphone': ['android']}}}, 'database': ['database management']}, 'computer hardware': {'mobile phone': {'telephone set': {'smartphone': ['android']}}}, 'software': {'computer control system': {'numerical control system': ['cnc']}, 'gps': ['in']}, 'operating system': ['linux'], 'computer imaging and vision': {'image processing': {'face recognition': ['face detection']}}}, 'web': {'fullstack': {'programming language': ['python', 'c++']}, 'backend': {'programming language': ['python', 'c++']}}, 'mobile': {'android': {'mobile sensor': ['camera']}}, 'game': {'game': {'game platform': {'desktop': ['linux']}, 'programming languge': ['python', 'c++']}}, 'devops': {'devops': {'web knowledge': {'operating system': ['linux']}, 'programming language': ['python', 'c++']}}, 'test': {'test': {'programming language': ['python'], 'test type': {'functional testing': {'system testing': ['linux']}}}}, 'softskill': {'softskill': {'communication': {'using foreign language': ['english']}}}}, 'linked_in': {'yaml': {'test for test purposes only': ['android', 'python', 'linux']}, 'creative': {'product and manufacturing': ['manufacturing']}, 'technology': ['database management'], 'business': {'business analysis and strategy': ['product management'], 'business software and tools': ['devices']}}}}\n"
     ]
    }
   ],
   "source": [
    "print(cso_classifier.build_graph(g_onto,skills, 0, {},{})[2])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96350e89b918eef37b6e497c0b867bc0d181ddadcfc87ab65b01a89441f72824"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('venv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
